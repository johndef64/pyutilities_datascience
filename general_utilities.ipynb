{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# General Utilities"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import zipfile\n",
    "import requests\n",
    "\n",
    "def simple_bool(message):\n",
    "    choose = input(message+\" (y/n): \").lower()\n",
    "    your_bool = choose in [\"y\", \"yes\",\"yea\",\"sure\"]\n",
    "    return your_bool"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Downloaders"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "\n",
    "class Downloader:\n",
    "\n",
    "    # git clone\n",
    "    def git_clone(repo_url, save_dir = os.getcwd()):\n",
    "        cmd = f'git clone {repo_url} {save_dir}'\n",
    "        os.system(cmd)\n",
    "\n",
    "    def git_clone_sub(repo_url,sub ,save_dir = os.getcwd()+'\\\\temp\\\\'):\n",
    "        cmd = f'git clone {repo_url} {save_dir}'\n",
    "        os.system(cmd)\n",
    "        # specify original path and destination path\n",
    "        original_path = save_dir + sub\n",
    "        destination_path = os.path.join(os.getcwd(), sub)\n",
    "        os.rename(original_path, destination_path)\n",
    "        delete = f'rmdir /s /q  {save_dir}'\n",
    "        os.system(delete)\n",
    "        print(save_dir)\n",
    "\n",
    "    # Simple Downloader\n",
    "    def get_file(url, file_name, dir = os.getcwd()):\n",
    "        response = requests.get(url)\n",
    "        if response.status_code == 200:\n",
    "            content = response.content\n",
    "            file_path = os.path.join(dir, file_name)\n",
    "            with open(file_path, 'wb') as file:\n",
    "                file.write(content)\n",
    "            print(f\"File downloaded successfully. Saved as {file_name}\")\n",
    "        else:\n",
    "            print(\"Unable to download the file.\")\n",
    "\n",
    "    # Download single GitHub file from repository\n",
    "    def get_gitfile(url, flag='', dir = os.getcwd()):\n",
    "        url = url.replace('blob','raw')\n",
    "        response = requests.get(url)\n",
    "        file_name = flag + url.rsplit('/',1)[1]\n",
    "        file_path = os.path.join(dir, file_name)\n",
    "        if response.status_code == 200:\n",
    "            with open(file_path, 'wb') as file:\n",
    "                file.write(response.content)\n",
    "            print(f\"File downloaded successfully. Saved as {file_name}\")\n",
    "        else:\n",
    "            print(\"Unable to download the file.\")\n",
    "\n",
    "    # Download and Exrtact zip file from Zenodo\n",
    "    def get_and_extract_zenodo(file, dir = os.getcwd(), ext = '.zip'):\n",
    "        url='https://zenodo.org/record/8205724/files/'+file+'.zip?download=1'\n",
    "        zip_file_name = file+ext\n",
    "        extracted_folder_name = dir\n",
    "        # Download the ZIP file\n",
    "        response = requests.get(url)\n",
    "        if response.status_code == 200:\n",
    "            # Extract the ZIP contents\n",
    "            with io.BytesIO(response.content) as zip_buffer:\n",
    "                with zipfile.ZipFile(zip_buffer, 'r') as zip_ref:\n",
    "                    zip_ref.extractall(extracted_folder_name)\n",
    "            print(f\"ZIP file '{zip_file_name}' extracted to '{extracted_folder_name}' successfully.\")\n",
    "        else:\n",
    "            print(\"Failed to download the ZIP file.\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\giova\\Documents\\GitHub\\pyutilities_datascience\\temp\\\n"
     ]
    }
   ],
   "source": [
    "Downloader.git_clone_sub('https://github.com/johndef64/pychatgpt.git', 'bash-gpt')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 2] Impossibile trovare il file specificato: 'C:\\\\Users\\\\giova\\\\Documents\\\\GitHub\\\\pyutilities_datascience\\\\temp/starfish' -> 'C:\\\\Users\\\\giova\\\\Documents\\\\GitHub\\\\pyutilities_datascience\\\\starfish'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[143], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mDownloaders\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgit_clone_sub\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mhttps://github.com/spacetx/starfish.git\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mstarfish\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[141], line 17\u001B[0m, in \u001B[0;36mDownloaders.git_clone_sub\u001B[1;34m(repo_url, sub, save_dir)\u001B[0m\n\u001B[0;32m     15\u001B[0m original_path \u001B[38;5;241m=\u001B[39m save_dir \u001B[38;5;241m+\u001B[39m sub\n\u001B[0;32m     16\u001B[0m destination_path \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(os\u001B[38;5;241m.\u001B[39mgetcwd(), sub)\n\u001B[1;32m---> 17\u001B[0m \u001B[43mos\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrename\u001B[49m\u001B[43m(\u001B[49m\u001B[43moriginal_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdestination_path\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     18\u001B[0m delete \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mrmdir /s /q  \u001B[39m\u001B[38;5;132;01m{\u001B[39;00msave_dir\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m     19\u001B[0m os\u001B[38;5;241m.\u001B[39msystem(delete)\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [WinError 2] Impossibile trovare il file specificato: 'C:\\\\Users\\\\giova\\\\Documents\\\\GitHub\\\\pyutilities_datascience\\\\temp/starfish' -> 'C:\\\\Users\\\\giova\\\\Documents\\\\GitHub\\\\pyutilities_datascience\\\\starfish'"
     ]
    }
   ],
   "source": [
    "Downloader.git_clone_sub('https://github.com/spacetx/starfish.git','starfish')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "outputs": [],
   "source": [
    "Downloader.git_clone('https://github.com/johndef64/pychatgpt.git', r'C:\\Users\\giova\\Documents\\GitHub\\pyutilities_datascience\\newrepo')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# CSV Datasets"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File downloaded successfully. Saved as base_pokemon.csv\n",
      "File downloaded successfully. Saved as go_pokemon.csv\n",
      "File downloaded successfully. Saved as H_GENES_proteincoding_genes.csv\n"
     ]
    }
   ],
   "source": [
    "# Download the file\n",
    "file1 = \"https://github.com/SeniorMars/pokemon-csv/blob/master/pokemon.csv\"\n",
    "file2 = \"https://github.com/zehnzwanzig/PokemonGo_CSV/blob/master/pokemon.csv\"\n",
    "file3 = 'https://github.com/johndef64/GRPM_system/blob/main/human_genes_repo/H_GENES_proteincoding_genes.csv'\n",
    "\n",
    "Downloader.get_gitfile(file1, 'base_')\n",
    "Downloader.get_gitfile(file2, 'go_'  )\n",
    "Downloader.get_gitfile(file3)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File downloaded successfully. Saved as gagaulala.csv\n"
     ]
    }
   ],
   "source": [
    "Downloader.get_file(file1,'gagaulala.csv')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# File Operartions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 4\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mglob\u001B[39;00m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mpandas\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mpd\u001B[39;00m\n\u001B[1;32m----> 4\u001B[0m \u001B[38;5;28;01mclass\u001B[39;00m \u001B[38;5;21;01mFile\u001B[39;00m:\n\u001B[0;32m      5\u001B[0m     \u001B[38;5;66;03m# Check files in folder (with extension)\u001B[39;00m\n\u001B[0;32m      6\u001B[0m     \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdisplay_file\u001B[39m(ext, contains\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m'\u001B[39m, path\u001B[38;5;241m=\u001B[39mos\u001B[38;5;241m.\u001B[39mgetcwd()):\n\u001B[0;32m      7\u001B[0m         file_pattern \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(path, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m*.\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m+\u001B[39mext)\n",
      "Cell \u001B[1;32mIn[1], line 6\u001B[0m, in \u001B[0;36mFile\u001B[1;34m()\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28;01mclass\u001B[39;00m \u001B[38;5;21;01mFile\u001B[39;00m:\n\u001B[0;32m      5\u001B[0m     \u001B[38;5;66;03m# Check files in folder (with extension)\u001B[39;00m\n\u001B[1;32m----> 6\u001B[0m     \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdisplay_file\u001B[39m(ext, contains\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m'\u001B[39m, path\u001B[38;5;241m=\u001B[39m\u001B[43mos\u001B[49m\u001B[38;5;241m.\u001B[39mgetcwd()):\n\u001B[0;32m      7\u001B[0m         file_pattern \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(path, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m*.\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m+\u001B[39mext)\n\u001B[0;32m      8\u001B[0m         files \u001B[38;5;241m=\u001B[39m glob\u001B[38;5;241m.\u001B[39mglob(file_pattern)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "class File:\n",
    "    # Check files in folder (with extension)\n",
    "    def display_file(ext, contains='', path=os.getcwd()):\n",
    "        file_pattern = os.path.join(path, \"*.\"+ext)\n",
    "        files = glob.glob(file_pattern)\n",
    "        files_name = []\n",
    "        for file in files:\n",
    "            file_name = os.path.basename(file)\n",
    "            files_name.append(file_name)\n",
    "\n",
    "        print('Available .'+ext+' files:')\n",
    "        files_df = pd.Series(files_name)\n",
    "        file = files_df[files_df.str.contains(contains)]\n",
    "        print(file)\n",
    "\n",
    "    def display_subfolders(folder_path=os.getcwd()):\n",
    "        subfolders = [f.name for f in os.scandir(folder_path) if f.is_dir()]\n",
    "        print(\"Subfolders in\", folder_path, \":\")\n",
    "        for subfolder in subfolders:\n",
    "            print(subfolder)\n",
    "\n",
    "    def get_subfolders(folder_path=os.getcwd()):\n",
    "        subfolders = [f.name for f in os.scandir(folder_path) if f.is_dir()]\n",
    "        return subfolders\n",
    "\n",
    "    def get_files(ext, contains='', path=os.getcwd()):\n",
    "        file_pattern = os.path.join(path, \"*.\"+ext)\n",
    "        files = glob.glob(file_pattern)\n",
    "        files_name = []\n",
    "        for file in files:\n",
    "            file_name = os.path.basename(file)\n",
    "            files_name.append(file_name)\n",
    "        filtered_file = [item for item in files_name if isinstance(item, str) and contains in item]\n",
    "        return filtered_file\n",
    "\n",
    "    def get_files_pd(ext, contains='', path=os.getcwd()):\n",
    "        # Create a file path pattern to match 'ext' files\n",
    "        file_pattern = os.path.join(path, \"*.\"+ext)\n",
    "        # Use glob to get a list of file paths matching the pattern\n",
    "        files = glob.glob(file_pattern)\n",
    "        files_name = []\n",
    "        # Get the list of 'ext' files\n",
    "        for file in files:\n",
    "            file_name = os.path.basename(file)\n",
    "            files_name.append(file_name)\n",
    "        files_sr = pd.Series(files_name)\n",
    "        filtered_file = files_sr[files_sr.str.contains(contains)]\n",
    "        return pd.Series(filtered_file)\n",
    "\n",
    "    def delete_file(filename, path=os.getcwd()):\n",
    "        try:\n",
    "            os.remove(os.path.join(path, filename))\n",
    "            print(f\"File {filename} deleted successfully.\")\n",
    "        except FileNotFoundError:\n",
    "            print(f\"File {filename} not found.\")\n",
    "        except PermissionError:\n",
    "            print(f\"Permission denied.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Unable to delete file {filename}. Error: {str(e)}\")\n",
    "\n",
    "File.display_file('csv')\n",
    "File.delete_file('H_GENES_proteincoding_genes.csv')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Display CSV"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "data": {
      "text/plain": "       # NAME_ENGLISH NAME_GERMAN    NAME_FRENCH   NAME_JAPAN    NAME_KOREAN  \\\n0      1    Bulbasaur     Bisasam     Bulbizarre  Fushigidane    Isanghaessi   \n1      2      Ivysaur   Bisaknosp     Herbizarre   Fushigisou    Isanghaepul   \n2      3     Venusaur    Bisaflor     Florizarre  Fushigibana   Isanghaekkot   \n3      4   Charmander    Glumanda      Salamèche     Hitokage          Pairi   \n4      5   Charmeleon     Glutexo      Reptincel      Lizardo        Rijadeu   \n..   ...          ...         ...            ...          ...            ...   \n837  805    Stakataka    Muramura       Ama-Ama   Tundetunde   Chagogchagog    \n838  806  Blacephalon   Kopplosio  Pierroteknik     Zugadoon       Dupapang    \n839  807      Zeraora     Zeraora       Zeraora      Zeraora        Jeraora    \n840  808       Meltan      Meltan        Meltan      Merutan         Meltan    \n841  809     Melmetal    Melmetal       Melmetal  Merumetaru       Melmetal    \n\n         TYP1    TYP2  GENERATION  CANDY  BUDDY_DISTANCE  MAX_HP  MAX_ATT  \\\n0       Grass  Poison         1.0   25.0             3.0   128.0    118.0   \n1       Grass  Poison         1.0  100.0             3.0   155.0    151.0   \n2       Grass  Poison         1.0    NaN             3.0   190.0    198.0   \n3        Fire     NaN         1.0   25.0             3.0   118.0    116.0   \n4        Fire     NaN         1.0  100.0             3.0   151.0    158.0   \n..        ...     ...         ...    ...             ...     ...      ...   \n837      Rock   Steel         7.0    NaN             NaN     NaN      NaN   \n838      Fire   Ghost         7.0    NaN             NaN     NaN      NaN   \n839  Electric     NaN         7.0    NaN             NaN     NaN      NaN   \n840     Steel     NaN         7.0  400.0            20.0   130.0    112.0   \n841     Steel     NaN         7.0    NaN            20.0   264.0    231.0   \n\n     MAX_DEF  MAX_CP CATCH_RATE ESCAPE_RATE SHINY       ICON_PATH  \\\n0      111.0  1115.0    20,00 %     10,00 %   Yes  ./icon/001.png   \n1      143.0  1699.0    10,00 %      7,00 %   Yes  ./icon/002.png   \n2      189.0  2720.0     5,00 %      5,00 %   Yes  ./icon/003.png   \n3       93.0   980.0    20,00 %     10,00 %   Yes  ./icon/004.png   \n4      126.0  1653.0    10,00 %      7,00 %   Yes  ./icon/005.png   \n..       ...     ...        ...         ...   ...             ...   \n837      NaN     NaN        NaN         NaN   NaN  ./icon/805.png   \n838      NaN     NaN        NaN         NaN   NaN  ./icon/806.png   \n839      NaN     NaN        NaN         NaN   NaN  ./icon/807.png   \n840    113.0  1080.0    30,00 %         NaN    No  ./icon/808.png   \n841    213.0  3875.0    30,00 %         NaN    No  ./icon/809.png   \n\n           SPRITE_PATH  \n0    ./sprites/001.png  \n1    ./sprites/002.png  \n2    ./sprites/003.png  \n3    ./sprites/004.png  \n4    ./sprites/005.png  \n..                 ...  \n837                NaN  \n838                NaN  \n839                NaN  \n840  ./sprites/808.png  \n841  ./sprites/809.png  \n\n[842 rows x 20 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>#</th>\n      <th>NAME_ENGLISH</th>\n      <th>NAME_GERMAN</th>\n      <th>NAME_FRENCH</th>\n      <th>NAME_JAPAN</th>\n      <th>NAME_KOREAN</th>\n      <th>TYP1</th>\n      <th>TYP2</th>\n      <th>GENERATION</th>\n      <th>CANDY</th>\n      <th>BUDDY_DISTANCE</th>\n      <th>MAX_HP</th>\n      <th>MAX_ATT</th>\n      <th>MAX_DEF</th>\n      <th>MAX_CP</th>\n      <th>CATCH_RATE</th>\n      <th>ESCAPE_RATE</th>\n      <th>SHINY</th>\n      <th>ICON_PATH</th>\n      <th>SPRITE_PATH</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>Bulbasaur</td>\n      <td>Bisasam</td>\n      <td>Bulbizarre</td>\n      <td>Fushigidane</td>\n      <td>Isanghaessi</td>\n      <td>Grass</td>\n      <td>Poison</td>\n      <td>1.0</td>\n      <td>25.0</td>\n      <td>3.0</td>\n      <td>128.0</td>\n      <td>118.0</td>\n      <td>111.0</td>\n      <td>1115.0</td>\n      <td>20,00 %</td>\n      <td>10,00 %</td>\n      <td>Yes</td>\n      <td>./icon/001.png</td>\n      <td>./sprites/001.png</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>Ivysaur</td>\n      <td>Bisaknosp</td>\n      <td>Herbizarre</td>\n      <td>Fushigisou</td>\n      <td>Isanghaepul</td>\n      <td>Grass</td>\n      <td>Poison</td>\n      <td>1.0</td>\n      <td>100.0</td>\n      <td>3.0</td>\n      <td>155.0</td>\n      <td>151.0</td>\n      <td>143.0</td>\n      <td>1699.0</td>\n      <td>10,00 %</td>\n      <td>7,00 %</td>\n      <td>Yes</td>\n      <td>./icon/002.png</td>\n      <td>./sprites/002.png</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>Venusaur</td>\n      <td>Bisaflor</td>\n      <td>Florizarre</td>\n      <td>Fushigibana</td>\n      <td>Isanghaekkot</td>\n      <td>Grass</td>\n      <td>Poison</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>3.0</td>\n      <td>190.0</td>\n      <td>198.0</td>\n      <td>189.0</td>\n      <td>2720.0</td>\n      <td>5,00 %</td>\n      <td>5,00 %</td>\n      <td>Yes</td>\n      <td>./icon/003.png</td>\n      <td>./sprites/003.png</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>Charmander</td>\n      <td>Glumanda</td>\n      <td>Salamèche</td>\n      <td>Hitokage</td>\n      <td>Pairi</td>\n      <td>Fire</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>25.0</td>\n      <td>3.0</td>\n      <td>118.0</td>\n      <td>116.0</td>\n      <td>93.0</td>\n      <td>980.0</td>\n      <td>20,00 %</td>\n      <td>10,00 %</td>\n      <td>Yes</td>\n      <td>./icon/004.png</td>\n      <td>./sprites/004.png</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>Charmeleon</td>\n      <td>Glutexo</td>\n      <td>Reptincel</td>\n      <td>Lizardo</td>\n      <td>Rijadeu</td>\n      <td>Fire</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>100.0</td>\n      <td>3.0</td>\n      <td>151.0</td>\n      <td>158.0</td>\n      <td>126.0</td>\n      <td>1653.0</td>\n      <td>10,00 %</td>\n      <td>7,00 %</td>\n      <td>Yes</td>\n      <td>./icon/005.png</td>\n      <td>./sprites/005.png</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>837</th>\n      <td>805</td>\n      <td>Stakataka</td>\n      <td>Muramura</td>\n      <td>Ama-Ama</td>\n      <td>Tundetunde</td>\n      <td>Chagogchagog</td>\n      <td>Rock</td>\n      <td>Steel</td>\n      <td>7.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>./icon/805.png</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>838</th>\n      <td>806</td>\n      <td>Blacephalon</td>\n      <td>Kopplosio</td>\n      <td>Pierroteknik</td>\n      <td>Zugadoon</td>\n      <td>Dupapang</td>\n      <td>Fire</td>\n      <td>Ghost</td>\n      <td>7.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>./icon/806.png</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>839</th>\n      <td>807</td>\n      <td>Zeraora</td>\n      <td>Zeraora</td>\n      <td>Zeraora</td>\n      <td>Zeraora</td>\n      <td>Jeraora</td>\n      <td>Electric</td>\n      <td>NaN</td>\n      <td>7.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>./icon/807.png</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>840</th>\n      <td>808</td>\n      <td>Meltan</td>\n      <td>Meltan</td>\n      <td>Meltan</td>\n      <td>Merutan</td>\n      <td>Meltan</td>\n      <td>Steel</td>\n      <td>NaN</td>\n      <td>7.0</td>\n      <td>400.0</td>\n      <td>20.0</td>\n      <td>130.0</td>\n      <td>112.0</td>\n      <td>113.0</td>\n      <td>1080.0</td>\n      <td>30,00 %</td>\n      <td>NaN</td>\n      <td>No</td>\n      <td>./icon/808.png</td>\n      <td>./sprites/808.png</td>\n    </tr>\n    <tr>\n      <th>841</th>\n      <td>809</td>\n      <td>Melmetal</td>\n      <td>Melmetal</td>\n      <td>Melmetal</td>\n      <td>Merumetaru</td>\n      <td>Melmetal</td>\n      <td>Steel</td>\n      <td>NaN</td>\n      <td>7.0</td>\n      <td>NaN</td>\n      <td>20.0</td>\n      <td>264.0</td>\n      <td>231.0</td>\n      <td>213.0</td>\n      <td>3875.0</td>\n      <td>30,00 %</td>\n      <td>NaN</td>\n      <td>No</td>\n      <td>./icon/809.png</td>\n      <td>./sprites/809.png</td>\n    </tr>\n  </tbody>\n</table>\n<p>842 rows × 20 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "         #           Name    Type 1  Type 2  Total   HP  Attack  Defense  \\\n0      1.0      Bulbasaur     Grass  Poison    318   45      49       49   \n1      2.0        Ivysaur     Grass  Poison    405   60      62       63   \n2      3.0       Venusaur     Grass  Poison    525   80      82       83   \n3      3.1  Mega Venusaur     Grass  Poison    625   80     100      123   \n4      4.0     Charmander      Fire     NaN    309   39      52       43   \n..     ...            ...       ...     ...    ...  ...     ...      ...   \n928  805.0      Stakataka      Rock   Steel    570   61     131      211   \n929  806.0    Blacephalon      Fire   Ghost    570   53     127       53   \n930  807.0        Zeraora  Electric     NaN    600   88     112       75   \n931  808.0         Meltan     Steel     NaN    300   65      46       65   \n932  809.0       Melmetal     Steel     NaN    600  135     143      143   \n\n     Sp. Atk  Sp. Def  Speed     Ability1     Ability2 Ability3  Generation  \\\n0         65       65     45     Overgrow  Chlorophyll      NaN           1   \n1         80       80     60     Overgrow  Chlorophyll      NaN           1   \n2        100      100     80     Overgrow  Chlorophyll      NaN           1   \n3        122      120     80    Thick Fat          NaN      NaN           1   \n4         60       50     65        Blaze  Solar Power      NaN           1   \n..       ...      ...    ...          ...          ...      ...         ...   \n928       53      101     13  Beast Boost          NaN      NaN           7   \n929      151       79    107  Beast Boost          NaN      NaN           7   \n930      102       80    143  Volt Absorb          NaN      NaN           7   \n931       55       35     34  Magnet Pull          NaN      NaN           7   \n932       80       65     34    Iron Fist          NaN      NaN           7   \n\n    Legendary  Mythical  \n0       FALSE     False  \n1       FALSE     False  \n2       FALSE     False  \n3       FALSE     False  \n4       FALSE     False  \n..        ...       ...  \n928     FALSE     False  \n929     FALSE     False  \n930      TRUE      True  \n931      TRUE      True  \n932      TRUE      True  \n\n[933 rows x 17 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>#</th>\n      <th>Name</th>\n      <th>Type 1</th>\n      <th>Type 2</th>\n      <th>Total</th>\n      <th>HP</th>\n      <th>Attack</th>\n      <th>Defense</th>\n      <th>Sp. Atk</th>\n      <th>Sp. Def</th>\n      <th>Speed</th>\n      <th>Ability1</th>\n      <th>Ability2</th>\n      <th>Ability3</th>\n      <th>Generation</th>\n      <th>Legendary</th>\n      <th>Mythical</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.0</td>\n      <td>Bulbasaur</td>\n      <td>Grass</td>\n      <td>Poison</td>\n      <td>318</td>\n      <td>45</td>\n      <td>49</td>\n      <td>49</td>\n      <td>65</td>\n      <td>65</td>\n      <td>45</td>\n      <td>Overgrow</td>\n      <td>Chlorophyll</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>FALSE</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2.0</td>\n      <td>Ivysaur</td>\n      <td>Grass</td>\n      <td>Poison</td>\n      <td>405</td>\n      <td>60</td>\n      <td>62</td>\n      <td>63</td>\n      <td>80</td>\n      <td>80</td>\n      <td>60</td>\n      <td>Overgrow</td>\n      <td>Chlorophyll</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>FALSE</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3.0</td>\n      <td>Venusaur</td>\n      <td>Grass</td>\n      <td>Poison</td>\n      <td>525</td>\n      <td>80</td>\n      <td>82</td>\n      <td>83</td>\n      <td>100</td>\n      <td>100</td>\n      <td>80</td>\n      <td>Overgrow</td>\n      <td>Chlorophyll</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>FALSE</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3.1</td>\n      <td>Mega Venusaur</td>\n      <td>Grass</td>\n      <td>Poison</td>\n      <td>625</td>\n      <td>80</td>\n      <td>100</td>\n      <td>123</td>\n      <td>122</td>\n      <td>120</td>\n      <td>80</td>\n      <td>Thick Fat</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>FALSE</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4.0</td>\n      <td>Charmander</td>\n      <td>Fire</td>\n      <td>NaN</td>\n      <td>309</td>\n      <td>39</td>\n      <td>52</td>\n      <td>43</td>\n      <td>60</td>\n      <td>50</td>\n      <td>65</td>\n      <td>Blaze</td>\n      <td>Solar Power</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>FALSE</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>928</th>\n      <td>805.0</td>\n      <td>Stakataka</td>\n      <td>Rock</td>\n      <td>Steel</td>\n      <td>570</td>\n      <td>61</td>\n      <td>131</td>\n      <td>211</td>\n      <td>53</td>\n      <td>101</td>\n      <td>13</td>\n      <td>Beast Boost</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>7</td>\n      <td>FALSE</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>929</th>\n      <td>806.0</td>\n      <td>Blacephalon</td>\n      <td>Fire</td>\n      <td>Ghost</td>\n      <td>570</td>\n      <td>53</td>\n      <td>127</td>\n      <td>53</td>\n      <td>151</td>\n      <td>79</td>\n      <td>107</td>\n      <td>Beast Boost</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>7</td>\n      <td>FALSE</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>930</th>\n      <td>807.0</td>\n      <td>Zeraora</td>\n      <td>Electric</td>\n      <td>NaN</td>\n      <td>600</td>\n      <td>88</td>\n      <td>112</td>\n      <td>75</td>\n      <td>102</td>\n      <td>80</td>\n      <td>143</td>\n      <td>Volt Absorb</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>7</td>\n      <td>TRUE</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>931</th>\n      <td>808.0</td>\n      <td>Meltan</td>\n      <td>Steel</td>\n      <td>NaN</td>\n      <td>300</td>\n      <td>65</td>\n      <td>46</td>\n      <td>65</td>\n      <td>55</td>\n      <td>35</td>\n      <td>34</td>\n      <td>Magnet Pull</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>7</td>\n      <td>TRUE</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>932</th>\n      <td>809.0</td>\n      <td>Melmetal</td>\n      <td>Steel</td>\n      <td>NaN</td>\n      <td>600</td>\n      <td>135</td>\n      <td>143</td>\n      <td>143</td>\n      <td>80</td>\n      <td>65</td>\n      <td>34</td>\n      <td>Iron Fist</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>7</td>\n      <td>TRUE</td>\n      <td>True</td>\n    </tr>\n  </tbody>\n</table>\n<p>933 rows × 17 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "poke_base = pd.read_csv('base_pokemon.csv')\n",
    "poke_go = pd.read_csv('go_pokemon.csv', encoding='latin-1')\n",
    "display(poke_go, poke_base)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "class Pandas:\n",
    "    # Df merger\n",
    "    def merge_base(df1, df2, column1, column2, how= ''):\n",
    "        merged_df = pd.merge(df1, df2, left_on=column1, right_on=column2, how=how)\n",
    "        return merged_df\n",
    "\n",
    "    def merge_select(df1, df2, how= 'inner'):\n",
    "        column1 = df1.columns[int(input(pd.Series(df1.columns)))]\n",
    "        column2 = df2.columns[int(input(pd.Series(df2.columns)))]\n",
    "        merged_df = pd.merge(df1, df2, left_on=column1, right_on=column2, how=how)\n",
    "        return merged_df\n",
    "\n",
    "    def merge_cross(df1, df2, how= 'cross'):\n",
    "        merged_df = pd.merge(df1, df2, how=how)\n",
    "        return merged_df\n",
    "\n",
    "    info = '''\n",
    "    The `how` parameter in `pd.merge` determines the type of merge to be performed. It's similar to the `JOIN` clause in SQL. Here are the options:\n",
    "\n",
    "    1. `how='inner'`: This is the default option. It returns only the rows in which the left and right dataframes have matching keys. This is equivalent to an SQL `INNER JOIN`.\n",
    "\n",
    "    2. `how='outer'`: This returns all the rows from both the left and right dataframes, and fills in `NaN` for missing matches on either side. This is equivalent to an SQL `FULL OUTER JOIN`.\n",
    "\n",
    "    3. `how='left'`: This returns all the rows from the left dataframe and the matched rows from the right dataframe. If there is no match, the result is `NaN` on the right side. This is equivalent to an SQL `LEFT OUTER JOIN`.\n",
    "\n",
    "    4. `how='right'`: This returns all the rows from the right dataframe and the matched rows from the left dataframe. If there is no match, the result is `NaN` on the left side. This is equivalent to an SQL `RIGHT OUTER JOIN`.\n",
    "\n",
    "    5. 'cross': creates the cartesian product from both frames, preserves the key order (available from pandas 1.2.0)\n",
    "   - This returns the Cartesian product of the two dataframes, i.e., each row from the first dataframe is combined with each row from the second dataframe.\n",
    "    '''"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [],
   "source": [
    "simple_df = Pandas.merge_select(poke_go, poke_base, 'inner')[['NAME_ENGLISH','NAME_FRENCH','Ability1']]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "outputs": [
    {
     "data": {
      "text/plain": "    NAME_ENGLISH    NAME_FRENCH     Ability1    nuova_colonna  new_col  \\\n0      Bulbasaur     Bulbizarre     Overgrow      Bulbasaur_0        0   \n1        Ivysaur     Herbizarre     Overgrow        Ivysaur_1        2   \n2       Venusaur     Florizarre     Overgrow       Venusaur_2        4   \n3     Charmander      Salamèche        Blaze     Charmander_3        6   \n4     Charmeleon      Reptincel        Blaze     Charmeleon_4        8   \n..           ...            ...          ...              ...      ...   \n797    Stakataka       Ama-Ama   Beast Boost    Stakataka_797     1594   \n798  Blacephalon  Pierroteknik   Beast Boost  Blacephalon_798     1596   \n799      Zeraora       Zeraora   Volt Absorb      Zeraora_799     1598   \n800       Meltan        Meltan   Magnet Pull       Meltan_800     1600   \n801     Melmetal       Melmetal    Iron Fist     Melmetal_801     1602   \n\n     new_col_2  \n0     0.000000  \n1     1.414214  \n2     2.000000  \n3     2.449490  \n4     2.828427  \n..         ...  \n797  39.924930  \n798  39.949969  \n799  39.974992  \n800  40.000000  \n801  40.024992  \n\n[802 rows x 6 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>NAME_ENGLISH</th>\n      <th>NAME_FRENCH</th>\n      <th>Ability1</th>\n      <th>nuova_colonna</th>\n      <th>new_col</th>\n      <th>new_col_2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Bulbasaur</td>\n      <td>Bulbizarre</td>\n      <td>Overgrow</td>\n      <td>Bulbasaur_0</td>\n      <td>0</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Ivysaur</td>\n      <td>Herbizarre</td>\n      <td>Overgrow</td>\n      <td>Ivysaur_1</td>\n      <td>2</td>\n      <td>1.414214</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Venusaur</td>\n      <td>Florizarre</td>\n      <td>Overgrow</td>\n      <td>Venusaur_2</td>\n      <td>4</td>\n      <td>2.000000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Charmander</td>\n      <td>Salamèche</td>\n      <td>Blaze</td>\n      <td>Charmander_3</td>\n      <td>6</td>\n      <td>2.449490</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Charmeleon</td>\n      <td>Reptincel</td>\n      <td>Blaze</td>\n      <td>Charmeleon_4</td>\n      <td>8</td>\n      <td>2.828427</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>797</th>\n      <td>Stakataka</td>\n      <td>Ama-Ama</td>\n      <td>Beast Boost</td>\n      <td>Stakataka_797</td>\n      <td>1594</td>\n      <td>39.924930</td>\n    </tr>\n    <tr>\n      <th>798</th>\n      <td>Blacephalon</td>\n      <td>Pierroteknik</td>\n      <td>Beast Boost</td>\n      <td>Blacephalon_798</td>\n      <td>1596</td>\n      <td>39.949969</td>\n    </tr>\n    <tr>\n      <th>799</th>\n      <td>Zeraora</td>\n      <td>Zeraora</td>\n      <td>Volt Absorb</td>\n      <td>Zeraora_799</td>\n      <td>1598</td>\n      <td>39.974992</td>\n    </tr>\n    <tr>\n      <th>800</th>\n      <td>Meltan</td>\n      <td>Meltan</td>\n      <td>Magnet Pull</td>\n      <td>Meltan_800</td>\n      <td>1600</td>\n      <td>40.000000</td>\n    </tr>\n    <tr>\n      <th>801</th>\n      <td>Melmetal</td>\n      <td>Melmetal</td>\n      <td>Iron Fist</td>\n      <td>Melmetal_801</td>\n      <td>1602</td>\n      <td>40.024992</td>\n    </tr>\n  </tbody>\n</table>\n<p>802 rows × 6 columns</p>\n</div>"
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nuova colonna con aggiunta\n",
    "import math\n",
    "import random\n",
    "simple_df['new_col'] = [(int(i))*2 for i in range(len(simple_df))]\n",
    "simple_df['new_col_2'] = simple_df['new_col'].apply(lambda x: math.sqrt(x))\n",
    "simple_df['new_col_3'] = simple_df['new_col_2'].apply(lambda x: x*random)\n",
    "simple_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "type object 'Pandas' has no attribute 'merge_dataframes_cross'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[81], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m simple_df \u001B[38;5;241m=\u001B[39m \u001B[43mPandas\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmerge_dataframes_cross\u001B[49m(poke_go[[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mNAME_ENGLISH\u001B[39m\u001B[38;5;124m'\u001B[39m,\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mNAME_FRENCH\u001B[39m\u001B[38;5;124m'\u001B[39m]], poke_base[[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mName\u001B[39m\u001B[38;5;124m'\u001B[39m,\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mAbility1\u001B[39m\u001B[38;5;124m'\u001B[39m]])\n",
      "\u001B[1;31mAttributeError\u001B[0m: type object 'Pandas' has no attribute 'merge_dataframes_cross'"
     ]
    }
   ],
   "source": [
    "Pandas.merge_cross(poke_go[['NAME_ENGLISH','NAME_FRENCH']], poke_base[['Name','Ability1']])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Get pychatgpt"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## other operations\n",
    "\n",
    "Ci sono molte operazioni che puoi eseguire sui DataFrame di Pandas. Ecco alcuni esempi:\n",
    "\n",
    "1. **Selezione dei dati**: Puoi selezionare dati specifici utilizzando il nome della colonna o condizioni specifiche.\n",
    "\n",
    "   ```python\n",
    "   df['colonna']  # seleziona una colonna\n",
    "   df[df['colonna'] > 0]  # seleziona righe dove 'colonna' è maggiore di 0\n",
    "   ```\n",
    "\n",
    "2. **Manipolazione dei dati**: Puoi modificare i tuoi dati in molti modi, come ad esempio aggiungere nuove colonne, modificare valori esistenti, ecc.\n",
    "\n",
    "   ```python\n",
    "   df['nuova_colonna'] = df['colonna1'] + df['colonna2']  # aggiunge una nuova colonna\n",
    "   df['colonna'] = df['colonna'].apply(lambda x: x*2)  # modifica i valori in 'colonna'\n",
    "   ```\n",
    "\n",
    "3. **Ordinamento**: Puoi ordinare i tuoi dati in base ai valori di una o più colonne.\n",
    "\n",
    "   ```python\n",
    "   df.sort_values(by='colonna')  # ordina in base a 'colonna'\n",
    "   ```\n",
    "\n",
    "4. **Grouping**: Puoi raggruppare i tuoi dati in base ai valori di una o più colonne e calcolare statistiche aggregate.\n",
    "\n",
    "   ```python\n",
    "   df.groupby('colonna').mean()  # calcola la media per ogni gruppo in 'colonna'\n",
    "   ```\n",
    "\n",
    "5. **Pivot**: Puoi pivotare i tuoi dati per creare una tabella pivot.\n",
    "\n",
    "   ```python\n",
    "   df.pivot_table(values='colonna1', index='colonna2', columns='colonna3')\n",
    "   ```\n",
    "\n",
    "6. **Join**: Oltre al merge, puoi anche unire DataFrame utilizzando `join`.\n",
    "\n",
    "   ```python\n",
    "   df1.join(df2, on='colonna_comune')\n",
    "   ```\n",
    "\n",
    "7. **Reshaping**: Puoi modificare la forma del tuo DataFrame utilizzando operazioni come `melt`, `pivot`, ecc.\n",
    "\n",
    "8. **Handling Missing Values**: Puoi gestire i valori mancanti utilizzando metodi come `dropna`, `fillna`, ecc.\n",
    "\n",
    "Questi sono solo alcuni esempi delle operazioni che puoi eseguire sui DataFrame di Pandas. Pandas è una libreria molto potente e flessibile che offre molte altre funzionalità."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File downloaded successfully. Saved as pychatgpt.py\n",
      "The Cosmic Holographic Principle is a concept in theoretical physics and cosmology that suggests that the information and structure of our entire universe may be encoded in two-dimensional surfaces, similar to a hologram. It proposes that our three-dimensional reality, including gravity and all the particles it contains, is actually a projection or a hologram of information encoded on the two-dimensional boundary of the universe.\n",
      "\n",
      "The idea originated from the study of black holes by physicist Jacob Bekenstein and was later developed by theoretical physicist Juan Maldacena and others. They proposed that the information contained within a black hole is proportional to the surface area of its event horizon rather than its volume, supporting the notion of a holographic representation of reality.\n",
      "\n",
      "According to the Cosmic Holographic Principle, the universe can be thought of as a three-dimensional projection of information stored on a two-dimensional surface at the edge of spacetime, often referred to as the \"cosmic horizon\" or the \"boundary of the universe.\" This boundary is analogous to the event horizon of a black hole and is sometimes called the \"holographic screen.\"\n",
      "\n",
      "The concept suggests that everything we observe and experience in our universe, including matter, energy, and the fundamental laws of physics, might be emergent properties arising from this underlying two-dimensional information. It implies a deep interconnectedness and fundamental unity of the cosmos, where each part of the universe contains information about the whole.\n",
      "\n",
      "The Cosmic Holographic Principle has far-reaching implications for our understanding of the nature of reality and has sparked considerable research and debate in the field of theoretical physics. It potentially offers insights into the nature of gravity, quantum mechanics, and the fundamental origins of the universe. However, it should be noted that the principle is still highly theoretical and has yet to be fully proven or incorporated into a complete scientific framework.\n",
      "prompt tokens: 719\n"
     ]
    }
   ],
   "source": [
    "# get & import pychatgpt (openai based module)\n",
    "if simple_bool('Do you have an openai API-key?'):\n",
    "    # Get pychatgpt at: https://github.com/johndef64/pychatgpt.git\n",
    "    url=\"https://raw.githubusercontent.com/johndef64/pychatgpt/main/pychatgpt.py\"\n",
    "    Downloader.get_gitfile(url)\n",
    "\n",
    "    import pychatgpt as op\n",
    "    # Example usage\n",
    "    message = \"Describe the Cosmic Holographic Principle\"\n",
    "    response = op.send_message_gpt(message, model='gpt-4')\n",
    "\n",
    "else:\n",
    "    print('get your api-key at https://platform.openai.com/account/api-keys\\n'\n",
    "          'or simply use web playground at https://platform.openai.com/playground?model=gpt-3.5-turbo-16k')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure, if you have two dataframes in pandas, you can use the merge() function to merge them based on a common column. Below is a sample function that accept the two dataframe and column names as input and performs the merging operation.\n",
      "\n",
      "```Python\n",
      "import pandas as pd\n",
      "\n",
      "def merge_dataframes(df1, df2, column1, column2):\n",
      "    merged_df = pd.merge(df1, df2, left_on=column1, right_on=column2, how='outer')\n",
      "    return merged_df\n",
      "```\n",
      "You can use this function to merge two dataframes. You just need to pass two dataframes and the column names you want to merge on as arguments.\n",
      "\n",
      "The 'how' parameter can take the values 'inner', 'outer', 'left', or 'right'. 'outer' returns all records when there is a match in either df1 or df2. 'inner' returns only the records where there is a match in both dfs. 'left' (or 'right') returns all the records from df1 (or df2) and the matched records from df2 (or df1), filling with NaNs where there is no match.\n",
      "\n",
      "Please remember to replace 'df1', 'df2', 'column1', and 'column2' with your actual dataframe names and column names you would like to merge on.\n",
      "prompt tokens: 1022\n"
     ]
    }
   ],
   "source": [
    "import pychatgpt as op\n",
    "\n",
    "op.send_message_gpt('''\n",
    "write a function in python optimized for the merging of two dataframe, also on different columns, in pandas\n",
    "\n",
    "''', model='gpt-4')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# open with notepad, subprocess"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "def open_in_notepadpp(file_path):\n",
    "    notepadpp_path = r\"C:\\Program Files\\Notepad++\\notepad++.exe\"  # Path to Notepad++ executable\n",
    "    subprocess.Popen([notepadpp_path, file_path])\n",
    "\n",
    "# Usage\n",
    "file_path = r\"conversation_log.txt\"  # Replace with the actual file path\n",
    "open_in_notepadpp(file_path)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Prompt for keyword-mesh"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Define Biomedical topics\n",
    "nutritional_topic = [['diseases and disorders realted to nutrition and diet ', 'diet, food consuption, eating behaviour and nutrition']]\n",
    "infective_topic = [['infective agents, bacteria, virus and protozoan','infective diseases']]\n",
    "reproductive_topic = [['reproductive system physiology','reproductive system pathology', 'Assisted reproductive technology']]\n",
    "female_infertility_topic = [['female infertility, genetic imprinting and maternal effect']]\n",
    "special_issue = [['Diagnosis and Therapies for Genetic Diseases']]\n",
    "\n",
    "nutritional_topics = [\n",
    "    ['Obesity, overweight and body weight control', 'compulsive eating behavior'],\n",
    "    ['cardiovascular diseases','physiological processes realted to cardiovascular diseases','lipid metabolism in the context of cardiovascular diseases'],\n",
    "    ['Diabetes Melitus Type II and metabolic syndrome'],\n",
    "    ['Vitamin metabolism and Vitamins recommended intake levels','Micronutrients metabolism and Micronutrient recommended intake levels', 'disease related to vitamins and micronutrients deficiency'],\n",
    "    ['eating behaviour and taste sensation'],\n",
    "    ['food intolerances'],\n",
    "    ['food allergies'],\n",
    "    ['diet-induced oxidative stress'],\n",
    "    ['metabolism of xenobiotics'],\n",
    "]\n",
    "chosen_topic = special_issue\n",
    "pd.Series(chosen_topic)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# GPT prompts\n",
    "\n",
    "# parameters--------------------------------------\n",
    "object1 = 'Pubmed MeSH terms'\n",
    "object2 = 'Pubmed keywords'\n",
    "\n",
    "object= object1\n",
    "num_mesh = 100\n",
    "topics = chosen_topic\n",
    "topic_id = 0\n",
    "#-----------------------------------------------\n",
    "topic_01  = topics[topic_id][0]\n",
    "topic_02  = topics[topic_id][1] if len(topics[topic_id])>=2 else None\n",
    "topic_03  = topics[topic_id][2] if len(topics[topic_id])>=3 else None\n",
    "\n",
    "format = {'list': \". Create a python list format like this:\\n gpt_01 = [\\\"term1\\\",\\n \\\"term2\\\",\\n \\\"term3\\\",...]\",\n",
    "          'csv':  \". Create a CSV file like this:\\n gpt_terms,\\n \\\"term1\\\",\\n \\\"term2\\\",\\n \\\"term3\\\", ...\"}\n",
    "format = format['csv']\n",
    "\n",
    "prompt_01 = \"give me a comprehensive list of \"+str(num_mesh)+\" real \"+object+\" terms related to \"+ topic_01+format+\"\\n\"\n",
    "prompt_02 = \"give me a comprehensive list of \"+str(num_mesh)+\" real \"+object+\" terms related to \"+ topic_02 +format+\"\\n\" if len(topics[topic_id])>=2 else None\n",
    "prompt_03 = \"give me a comprehensive list of \"+str(num_mesh)+\" real \"+object+\" terms related to \"+ topic_03 +format+\"\\n\" if len(topics[topic_id])>=3 else None\n",
    "\n",
    "prompts = [prompt_01, prompt_02, prompt_03]\n",
    "# If you do not have an openai API key, paste these prompts at https://platform.openai.com/playground?model=gpt-3.5-turbo-16k\n",
    "\n",
    "import pyperclip\n",
    "pyperclip.copy(prompt_01)\n",
    "pyperclip.copy(prompt_01+prompt_02) if len(topics[topic_id])>=2 else None\n",
    "pyperclip.copy(prompt_01+prompt_02+prompt_03) if len(topics[topic_id])>=3 else None\n",
    "\n",
    "print('prompt_01:',prompt_01)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# get GPT-terms\n",
    "import pychatgpt as op\n",
    "op.conversation_gpt =[]\n",
    "response = op.send_message_gpt(prompt_01, model='gpt-4', maxtoken=2000)\n",
    "#response = op.send_message_gpt('clearchat')\n",
    "\n",
    "print('''\\n\\nGet the GPT terms from 'conversation_log.txt'\n",
    "=> save them manually in csv format in \"ref-mesh-archive/gpt_terms/yourterms.csv\"''')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "file_path = 'special_issue_2.csv'\n",
    "content = '''gpt_terms\n",
    "\"Genetic Diseases Diagnosis\",\n",
    "\"Genetic Testing\",\n",
    "\"Molecular Diagnostics\",\n",
    "\"Genetic Screenings\",\n",
    "\"DNA Sequencing\",\n",
    "\"Genome Mapping\",\n",
    "\"Chromosomal Abnormalities\",\n",
    "\"Prenatal Diagnosis\",\n",
    "\"Newborn Screening\",\n",
    "\"Personalized Medicine\",\n",
    "\"Genetic Counseling\",\n",
    "\"Carrier Testing\",\n",
    "\"Genomic Medicine\",\n",
    "\"Pharmacogenetics\",\n",
    "\"Predictive Testing\",\n",
    "\"Presymptomatic Testing\",\n",
    "\"Biochemical Testing\",\n",
    "\"Genetic Therapies\",\n",
    "\"Gene Therapy\",\n",
    "\"Gene Editing\",\n",
    "\"CRISPR-Cas9\",\n",
    "\"Stem Cell Therapy\",\n",
    "\"RNA Therapy\",\n",
    "\"Genetic Surgery\",\n",
    "\"Molecular Therapy\",\n",
    "\"Enzyme Replacement Therapy\",\n",
    "\"Antisense Therapy\",\n",
    "\"Gene Silencing\",\n",
    "\"Genetic Vaccine\",\n",
    "\"Pharmacological Chaperones\"\n",
    "'''\n",
    "def write_to_file(file_path, content):\n",
    "    with open(file_path, 'w') as file:\n",
    "        file.write(content)\n",
    "\n",
    "write_to_file(file_path, content)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "op.send_message_gpt('how to say, if a apackahger is not instaled, intall it?')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# GET ZENODO NBIB Dataset (full)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import sys\n",
    "import glob\n",
    "import zipfile\n",
    "import requests\n",
    "from datetime import datetime\n",
    "\n",
    "def simple_bool(message):\n",
    "    choose = input(message+\" (y/n): \").lower()\n",
    "    your_bool = choose in [\"y\", \"yes\",\"yea\",\"sure\"]\n",
    "    return your_bool\n",
    "\n",
    "def get_and_extract(file, dir = os.getcwd(), ext = '.zip'):\n",
    "    url='https://zenodo.org/record/8205724/files/'+file+'.zip?download=1'\n",
    "    zip_file_name = file+ext\n",
    "    extracted_folder_name = dir\n",
    "    # Download the ZIP file\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        # Extract the ZIP contents\n",
    "        with io.BytesIO(response.content) as zip_buffer:\n",
    "            with zipfile.ZipFile(zip_buffer, 'r') as zip_ref:\n",
    "                zip_ref.extractall(extracted_folder_name)\n",
    "        print(f\"ZIP file '{zip_file_name}' extracted to '{extracted_folder_name}' successfully.\")\n",
    "    else:\n",
    "        print(\"Failed to download the ZIP file.\")\n",
    "\n",
    "if simple_bool('Download nbib-data from Zenodo?\\n (careful! 5GB unpacked)'):\n",
    "    timea = datetime.now()\n",
    "    get_and_extract('nbib_data')\n",
    "    print('Download and extraction time ',datetime.now()-timea)\n",
    "\n",
    "#set source dataset:-----------------------\n",
    "db_tag = 'pcg'\n",
    "db_name = 'grpm_db_' + db_tag\n",
    "db_path = 'grpm_dataset/'+db_name\n",
    "\n",
    "time1 = datetime.now()\n",
    "#import gene-fullnbib\n",
    "dummy_nbib = pd.read_csv(db_path+'/complete_nbibtable.csv', index_col=0)\n",
    "dummy_nbib['pubmed_id'] = dummy_nbib['pubmed_id'].astype(str)\n",
    "time2 = datetime.now()\n",
    "print('time import nbib: ', time2-time1)\n",
    "print(dummy_nbib.memory_usage().sum() / 1024 / 1024, 'MB')\n",
    "\n",
    "display(dummy_nbib)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# R in Python"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "You can run R code in a Jupyter notebook. You need to install the rpy2 package and load the R extension in Jupyter using the following steps:\n",
    "\n",
    "1. Install the rpy2 package using pip (Python's package installer). In a command line window run:\n",
    "   ```bash\n",
    "   pip install rpy2\n",
    "   ```\n",
    "\n",
    "2. Then, in your Jupyter notebook, load the rpy2 extension by adding this to a cell and running it:\n",
    "   ```python\n",
    "   %load_ext rpy2.ipython\n",
    "   ```\n",
    "\n",
    "3. Now you can use R in any cell by starting the cell with `%%R`. For example:\n",
    "   ```python\n",
    "   %%R\n",
    "   x <- seq(0, 2*pi, length.out=50)\n",
    "   y <- sin(x)\n",
    "   plot(x, y, main=\"y = sin(x)\")\n",
    "   ```\n",
    "\n",
    "Remember, the rpy2 package requires that R is installed on your machine and it relies on dynamic libraries that R uses, so be sure you have installed R and it is findable by rpy2."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rpy2\n",
      "  Downloading rpy2-3.5.14.tar.gz (219 kB)\n",
      "     ---------------------------------------- 0.0/219.3 kB ? eta -:--:--\n",
      "     -------------------------------------  215.0/219.3 kB 6.6 MB/s eta 0:00:01\n",
      "     -------------------------------------- 219.3/219.3 kB 4.4 MB/s eta 0:00:00\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: jinja2 in c:\\users\\giova\\.conda\\envs\\myenv01\\lib\\site-packages (from rpy2) (3.1.2)\n",
      "Collecting tzlocal\n",
      "  Downloading tzlocal-5.0.1-py3-none-any.whl (20 kB)\n",
      "Requirement already satisfied: cffi>=1.10.0 in c:\\users\\giova\\.conda\\envs\\myenv01\\lib\\site-packages (from rpy2) (1.15.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\giova\\.conda\\envs\\myenv01\\lib\\site-packages (from rpy2) (23.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\giova\\.conda\\envs\\myenv01\\lib\\site-packages (from cffi>=1.10.0->rpy2) (2.21)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\giova\\.conda\\envs\\myenv01\\lib\\site-packages (from jinja2->rpy2) (2.1.1)\n",
      "Collecting tzdata\n",
      "  Using cached tzdata-2023.3-py2.py3-none-any.whl (341 kB)\n",
      "Building wheels for collected packages: rpy2\n",
      "  Building wheel for rpy2 (pyproject.toml): started\n",
      "  Building wheel for rpy2 (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for rpy2: filename=rpy2-3.5.14-py3-none-any.whl size=220698 sha256=4e3a3c2aad41071a0d37420d20a6d3501089a05f117717d390a964193833c182\n",
      "  Stored in directory: c:\\users\\giova\\appdata\\local\\pip\\cache\\wheels\\d4\\b5\\2f\\529c5de71addd73d8e3c51104721d9e084c97ed2ce1c69de2d\n",
      "Successfully built rpy2\n",
      "Installing collected packages: tzdata, tzlocal, rpy2\n",
      "Successfully installed rpy2-3.5.14 tzdata-2023.3 tzlocal-5.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install rpy2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\giova\\.conda\\envs\\myenv01\\lib\\site-packages\\rpy2\\robjects\\packages.py:367: UserWarning: The symbol 'quartz' is not in this R namespace/package.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "%load_ext rpy2.ipython"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": "<IPython.core.display.Image object>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%R\n",
    "x <- seq(0, 2*pi, length.out=50)\n",
    "y <- sin(x)\n",
    "plot(x, y, main=\"y = sin(x)\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Repo Links"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "outputs": [],
   "source": [
    "# quick open in colab\n",
    "\n",
    "handle = \"https://colab.research.google.com/github/\"\n",
    "path = \"johndef64/pychatgpt/blob/main/pychatgpt_trial.ipynb\"\n",
    "path1 = \"spacetx/starfish/blob/master/notebooks/DARTFISH.ipynb\"\n",
    "import pyperclip\n",
    "pyperclip.copy(handle+path1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

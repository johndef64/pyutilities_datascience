{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# General Utilities"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import zipfile\n",
    "import requests\n",
    "\n",
    "def simple_bool(message):\n",
    "    choose = input(message+\" (y/n): \").lower()\n",
    "    your_bool = choose in [\"y\", \"yes\",\"yea\",\"sure\"]\n",
    "    return your_bool\n",
    "\n",
    "def get_file(url, file_name, dir = os.getcwd()):\n",
    "    url = url\n",
    "    file_name = file_name\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        content = response.content\n",
    "        file_path = os.path.join(dir, file_name)\n",
    "        with open(file_path, 'wb') as file:\n",
    "            file.write(content)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Download and Exrtact zip file from Zenodo"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_and_extract_zenodo(file, dir = os.getcwd(), ext = '.zip'):\n",
    "    url='https://zenodo.org/record/8205724/files/'+file+'.zip?download=1'\n",
    "    zip_file_name = file+ext\n",
    "    extracted_folder_name = dir\n",
    "    # Download the ZIP file\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        # Extract the ZIP contents\n",
    "        with io.BytesIO(response.content) as zip_buffer:\n",
    "            with zipfile.ZipFile(zip_buffer, 'r') as zip_ref:\n",
    "                zip_ref.extractall(extracted_folder_name)\n",
    "        print(f\"ZIP file '{zip_file_name}' extracted to '{extracted_folder_name}' successfully.\")\n",
    "    else:\n",
    "        print(\"Failed to download the ZIP file.\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Download single GitHub file from repository"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def get_gitfile(url, flag =''):\n",
    "    url = url.replace('blob','raw')\n",
    "    response = requests.get(url)\n",
    "    filename = flag + url.rsplit('/',1)[1]\n",
    "    if response.status_code == 200:\n",
    "        with open(filename, 'wb') as file:\n",
    "            file.write(response.content)\n",
    "        print(f\"File downloaded successfully. Saved as {filename}\")\n",
    "    else:\n",
    "        print(\"Unable to download the file.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# CSV Datasets"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Download the file\n",
    "file1 = \"https://github.com/SeniorMars/pokemon-csv/blob/master/pokemon.csv\"\n",
    "file2 = \"https://github.com/zehnzwanzig/PokemonGo_CSV/blob/master/pokemon.csv\"\n",
    "file3 = ''\n",
    "\n",
    "get_gitfile(file1, 'base_')\n",
    "get_gitfile(file2, 'go_')\n",
    "get_gitfile(file3, 'new_')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Check files in folder (with extension)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "def display_file(ext, folder_path=os.getcwd(), contains=''):\n",
    "    file_pattern = os.path.join(folder_path, \"*.\"+ext)\n",
    "    csv_files = glob.glob(file_pattern)\n",
    "    csv_files_name = []\n",
    "    for file in csv_files:\n",
    "        file_name = os.path.basename(file)\n",
    "        csv_files_name.append(file_name)\n",
    "\n",
    "    print('Available .'+ext+' files:')\n",
    "    files_df = pd.Series(csv_files_name)\n",
    "    file = files_df[files_df.str.contains(contains)]\n",
    "    print(file)\n",
    "\n",
    "display_file('csv')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Display CSV"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "poke_base = pd.read_csv('base_pokemon.csv')\n",
    "poke_go = pd.read_csv('go_pokemon.csv', encoding='latin-1')\n",
    "display(poke_go, poke_base)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Get pychatgpt"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# get & import pychatgpt (openai based module)\n",
    "if simple_bool('Do you have an openai API-key?'):\n",
    "    # Get pychatgpt at: https://github.com/johndef64/pychatgpt.git\n",
    "    get_file(url=\"https://raw.githubusercontent.com/johndef64/pychatgpt/main/pychatgpt.py\", file_name='pychatgpt.py')\n",
    "\n",
    "    import pychatgpt as op\n",
    "    # Example usage\n",
    "    message = \"Describe Nutrigenetics\"\n",
    "    response = op.send_message_gpt(message)\n",
    "\n",
    "else:\n",
    "    print('get your api-key at https://platform.openai.com/account/api-keys\\n'\n",
    "          'or simply use web playground at https://platform.openai.com/playground?model=gpt-3.5-turbo-16k')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pychatgpt as op\n",
    "\n",
    "op.send_message_gpt('''\n",
    "\n",
    "\n",
    "poke_base = pd.read_csv('base_pokemon.csv')\n",
    "poke_go = pd.read_csv('go_pokemon.csv', encoding='utf-8')\n",
    "display(poke_go, poke_base)\n",
    "\n",
    "\n",
    "UnicodeDecodeError: 'utf-8' codec can't decode byte 0x91 in position 8: invalid start byte''')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Prompt for keyword-mesh"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Define Biomedical topics\n",
    "nutritional_topic = [['diseases and disorders realted to nutrition and diet ', 'diet, food consuption, eating behaviour and nutrition']]\n",
    "infective_topic = [['infective agents, bacteria, virus and protozoan','infective diseases']]\n",
    "reproductive_topic = [['reproductive system physiology','reproductive system pathology', 'Assisted reproductive technology']]\n",
    "female_infertility_topic = [['female infertility, genetic imprinting and maternal effect']]\n",
    "special_issue = [['Diagnosis and Therapies for Genetic Diseases']]\n",
    "\n",
    "nutritional_topics = [\n",
    "    ['Obesity, overweight and body weight control', 'compulsive eating behavior'],\n",
    "    ['cardiovascular diseases','physiological processes realted to cardiovascular diseases','lipid metabolism in the context of cardiovascular diseases'],\n",
    "    ['Diabetes Melitus Type II and metabolic syndrome'],\n",
    "    ['Vitamin metabolism and Vitamins recommended intake levels','Micronutrients metabolism and Micronutrient recommended intake levels', 'disease related to vitamins and micronutrients deficiency'],\n",
    "    ['eating behaviour and taste sensation'],\n",
    "    ['food intolerances'],\n",
    "    ['food allergies'],\n",
    "    ['diet-induced oxidative stress'],\n",
    "    ['metabolism of xenobiotics'],\n",
    "]\n",
    "chosen_topic = special_issue\n",
    "pd.Series(chosen_topic)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# GPT prompts\n",
    "\n",
    "# parameters--------------------------------------\n",
    "object1 = 'Pubmed MeSH terms'\n",
    "object2 = 'Pubmed keywords'\n",
    "\n",
    "object= object1\n",
    "num_mesh = 100\n",
    "topics = chosen_topic\n",
    "topic_id = 0\n",
    "#-----------------------------------------------\n",
    "topic_01  = topics[topic_id][0]\n",
    "topic_02  = topics[topic_id][1] if len(topics[topic_id])>=2 else None\n",
    "topic_03  = topics[topic_id][2] if len(topics[topic_id])>=3 else None\n",
    "\n",
    "format = {'list': \". Create a python list format like this:\\n gpt_01 = [\\\"term1\\\",\\n \\\"term2\\\",\\n \\\"term3\\\",...]\",\n",
    "          'csv':  \". Create a CSV file like this:\\n gpt_terms,\\n \\\"term1\\\",\\n \\\"term2\\\",\\n \\\"term3\\\", ...\"}\n",
    "format = format['csv']\n",
    "\n",
    "prompt_01 = \"give me a comprehensive list of \"+str(num_mesh)+\" real \"+object+\" terms related to \"+ topic_01+format+\"\\n\"\n",
    "prompt_02 = \"give me a comprehensive list of \"+str(num_mesh)+\" real \"+object+\" terms related to \"+ topic_02 +format+\"\\n\" if len(topics[topic_id])>=2 else None\n",
    "prompt_03 = \"give me a comprehensive list of \"+str(num_mesh)+\" real \"+object+\" terms related to \"+ topic_03 +format+\"\\n\" if len(topics[topic_id])>=3 else None\n",
    "\n",
    "prompts = [prompt_01, prompt_02, prompt_03]\n",
    "# If you do not have an openai API key, paste these prompts at https://platform.openai.com/playground?model=gpt-3.5-turbo-16k\n",
    "\n",
    "import pyperclip\n",
    "pyperclip.copy(prompt_01)\n",
    "pyperclip.copy(prompt_01+prompt_02) if len(topics[topic_id])>=2 else None\n",
    "pyperclip.copy(prompt_01+prompt_02+prompt_03) if len(topics[topic_id])>=3 else None\n",
    "\n",
    "print('prompt_01:',prompt_01)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# get GPT-terms\n",
    "import pychatgpt as op\n",
    "op.conversation_gpt =[]\n",
    "response = op.send_message_gpt(prompt_01, model='gpt-4', maxtoken=2000)\n",
    "#response = op.send_message_gpt('clearchat')\n",
    "\n",
    "print('''\\n\\nGet the GPT terms from 'conversation_log.txt'\n",
    "=> save them manually in csv format in \"ref-mesh-archive/gpt_terms/yourterms.csv\"''')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "file_path = 'special_issue_2.csv'\n",
    "content = '''gpt_terms\n",
    "\"Genetic Diseases Diagnosis\",\n",
    "\"Genetic Testing\",\n",
    "\"Molecular Diagnostics\",\n",
    "\"Genetic Screenings\",\n",
    "\"DNA Sequencing\",\n",
    "\"Genome Mapping\",\n",
    "\"Chromosomal Abnormalities\",\n",
    "\"Prenatal Diagnosis\",\n",
    "\"Newborn Screening\",\n",
    "\"Personalized Medicine\",\n",
    "\"Genetic Counseling\",\n",
    "\"Carrier Testing\",\n",
    "\"Genomic Medicine\",\n",
    "\"Pharmacogenetics\",\n",
    "\"Predictive Testing\",\n",
    "\"Presymptomatic Testing\",\n",
    "\"Biochemical Testing\",\n",
    "\"Genetic Therapies\",\n",
    "\"Gene Therapy\",\n",
    "\"Gene Editing\",\n",
    "\"CRISPR-Cas9\",\n",
    "\"Stem Cell Therapy\",\n",
    "\"RNA Therapy\",\n",
    "\"Genetic Surgery\",\n",
    "\"Molecular Therapy\",\n",
    "\"Enzyme Replacement Therapy\",\n",
    "\"Antisense Therapy\",\n",
    "\"Gene Silencing\",\n",
    "\"Genetic Vaccine\",\n",
    "\"Pharmacological Chaperones\"\n",
    "'''\n",
    "def write_to_file(file_path, content):\n",
    "    with open(file_path, 'w') as file:\n",
    "        file.write(content)\n",
    "\n",
    "write_to_file(file_path, content)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "op.send_message_gpt('how to say, if a apackahger is not instaled, intall it?')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# open with notepad, subprocess"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "def open_in_notepadpp(file_path):\n",
    "    notepadpp_path = r\"C:\\Program Files\\Notepad++\\notepad++.exe\"  # Path to Notepad++ executable\n",
    "    subprocess.Popen([notepadpp_path, file_path])\n",
    "\n",
    "# Usage\n",
    "file_path = r\"conversation_log.txt\"  # Replace with the actual file path\n",
    "open_in_notepadpp(file_path)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# GET ZENODO NBIB Dataset (full)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import sys\n",
    "import glob\n",
    "import zipfile\n",
    "import requests\n",
    "from datetime import datetime\n",
    "\n",
    "def simple_bool(message):\n",
    "    choose = input(message+\" (y/n): \").lower()\n",
    "    your_bool = choose in [\"y\", \"yes\",\"yea\",\"sure\"]\n",
    "    return your_bool\n",
    "\n",
    "def get_and_extract(file, dir = os.getcwd(), ext = '.zip'):\n",
    "    url='https://zenodo.org/record/8205724/files/'+file+'.zip?download=1'\n",
    "    zip_file_name = file+ext\n",
    "    extracted_folder_name = dir\n",
    "    # Download the ZIP file\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        # Extract the ZIP contents\n",
    "        with io.BytesIO(response.content) as zip_buffer:\n",
    "            with zipfile.ZipFile(zip_buffer, 'r') as zip_ref:\n",
    "                zip_ref.extractall(extracted_folder_name)\n",
    "        print(f\"ZIP file '{zip_file_name}' extracted to '{extracted_folder_name}' successfully.\")\n",
    "    else:\n",
    "        print(\"Failed to download the ZIP file.\")\n",
    "\n",
    "if simple_bool('Download nbib-data from Zenodo?\\n (careful! 5GB unpacked)'):\n",
    "    timea = datetime.now()\n",
    "    get_and_extract('nbib_data')\n",
    "    print('Download and extraction time ',datetime.now()-timea)\n",
    "\n",
    "#set source dataset:-----------------------\n",
    "db_tag = 'pcg'\n",
    "db_name = 'grpm_db_' + db_tag\n",
    "db_path = 'grpm_dataset/'+db_name\n",
    "\n",
    "time1 = datetime.now()\n",
    "#import gene-fullnbib\n",
    "dummy_nbib = pd.read_csv(db_path+'/complete_nbibtable.csv', index_col=0)\n",
    "dummy_nbib['pubmed_id'] = dummy_nbib['pubmed_id'].astype(str)\n",
    "time2 = datetime.now()\n",
    "print('time import nbib: ', time2-time1)\n",
    "print(dummy_nbib.memory_usage().sum() / 1024 / 1024, 'MB')\n",
    "\n",
    "display(dummy_nbib)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
